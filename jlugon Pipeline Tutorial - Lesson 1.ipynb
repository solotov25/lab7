{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##ayvelasquezma Why Pipeline?\n",
    "Many trading algorithms have the following structure:\n",
    "1. For each asset in a known (large) set, compute N scalar values for the asset based on a trailing window of data.\n",
    "2. Select a smaller tradeable set of assets based on the values computed in (1).\n",
    "3. Calculate desired portfolio weights on the set of assets selected in (2).\n",
    "4. Place orders to move the algorithmâ€™s current portfolio allocations to the desired weights computed in (3).\n",
    "\n",
    "There are several technical challenges with doing this robustly. These include:\n",
    "\n",
    "- efficiently querying large sets of assets\n",
    "- performing computations on large sets of assets\n",
    "- handling adjustments (splits and dividends)\n",
    "- asset delistings\n",
    "\n",
    "Pipeline exists to solve these challenges by providing a uniform API for expressing computations on a diverse collection of datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Research and the IDE\n",
    "An ideal algorithm design workflow involves a research phase and an implementation phase. In the research environment, we can interact with data or quickly iterate on different ideas in a [notebook](https://ipython.org/notebook.html). Algorithms are implemented in the IDE where they can be backtested.\n",
    "\n",
    "One feature of the Pipeline API is that constructing a pipeline is identical in research and the IDE. The only difference between using pipeline in the two environments is how it is run. This makes it easy to iterate on a pipeline design in research and then move it with a simple copy paste to an algorithm in the IDE. This is a workflow that will be discussed explicitly in later lessons but will be observed throughout the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Computations\n",
    "There are three types of computations that can be expressed in a pipeline: $factors$, $filters$, and $classifiers$.\n",
    "    \n",
    "Abstractly, factors, filters, and classifiers all represent functions that produce a value from an asset and a moment in time. Factors, filters, and classifiers are distinguished by the $types$ of values they produce.\n",
    "\n",
    "\n",
    "Factors\n",
    "\n",
    "A factor is a function from an asset and a moment in time to a $numerical$ $value$.\n",
    "\n",
    "A simple example of a factor is the most recent price of a security. Given a security and a specific point in time, the most recent price is a number. Another example is the 10-day average trading volume of a security. Factors are most commonly used to assign values to securities which can then be used in a number of ways. A factor can be used in each of the following procedures:\n",
    "\n",
    "- computing target weights\n",
    "- generating alpha signal\n",
    "- constructing other, more complex factors\n",
    "- constructing filters\n",
    "\n",
    "Filters\n",
    "\n",
    "A filter is a function from an asset and a moment in time to a $boolean$.\n",
    "\n",
    "An example of a filter is a function indicating whether a security's price is below $10. Given a security and a point in time, this evaluates to either `True` or `False`. Filters are most commonly used for describing sets of assets to include or exclude for some particular purpose.\n",
    "\n",
    "Classifiers\n",
    "\n",
    "A classifier is a function from an asset and a moment in time to a $categorical$ $output$.\n",
    "\n",
    "More specifically, a classifier produces a `string` or an `int` that doesn't represent a numerical value (e.g. an integer label such as a sector code). Classifiers are most commonly used for grouping assets for complex transformations on Factor outputs. An example of a classifier is the exchange on which an asset is currently being traded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Datasets\n",
    "\n",
    "Pipeline computations can be performed using [a variety of data](https://www.quantopian.com/docs/data-reference/overview) such as [pricing (OHLC) and volume data, fundamentals](https://www.quantopian.com/docs/data-reference/daily_pricing) and [consensus estimates](https://www.quantopian.com/docs/data-reference/estimates_consensus). We will explore these datasets in later lessons.\n",
    "\n",
    "A typical pipeline usually involves multiple computations and datasets. In this tutorial, we will build up to a pipeline that selects liquid securities with large changes between their 10-day and 30-day average prices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
